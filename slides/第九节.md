# 第九课-自制深度学习推理框架-实现Yolov5网络的推理

> 作者：傅莘莘
>
> 主项目：https://github.com/zjhellofss/KuiperInfer 欢迎大家点赞和PR.
>
> 课程代码：https://github.com/zjhellofss/kuiperdatawhale/course9

![](https://i.imgur.com/qO2yKaH.jpg)

## Yolov5中的预处理


预处理的作用与上一节中的ResNet网络中的预处理函数类似,主要包括以下几个步骤:

1. 图像缩放
2. 图像补边
3. 颜色空间转换
4. 图像归一化
5. 将RGBRGBRGB的像素格式转换为RRRGGGBBB的像素格式，也就是将像素排布从HWC到CHW。

Yolov5定义了一个`PreProcessImage`函数来完成图像的预处理，在这个函数中依次调用了图像缩放、补边等如上的图像预处理流程。

### 图像缩放和补边

<img src="https://img-blog.csdnimg.cn/402d3a22b1d6439393bf9a14e700d196.jpeg" alt="dem113" style="zoom: 80%;" />

如上图所示，在`YOLOv5`中，补边（padding）是一种数据预处理技术。它的作用是在输入图像的周围添加额外的像素，以保证图像能够被整除到指定的尺寸。图像缩放和补边的实现在`LetterBox`方法中，该方法的参数定义如下：

```cpp
float Letterbox(
    const cv::Mat &image,
    cv::Mat &out_image,
    const cv::Size &new_shape = cv::Size(640, 640),
    int stride = 32,
    const cv::Scalar &color = cv::Scalar(114, 114, 114),
    bool fixed_shape = false,
    bool scale_up = false);
```

该函数主要有以下几个参数，`image`是我们输入的原始图像，`out_image`是经过预处理后的输出图像。`new_shape`是需要缩放到的目标大小，**一般设置为`YOLOv5`模型输入的大小**，此处默认为$640 \times 640$. `Color`参数表示补边时所使用的颜色，其他参数并不是不是重点，我们可以默认将它们设为`false`.

```cpp
float Letterbox(...){
	...
    cv::Size shape = image.size();
    float r = std::min((float) new_shape.height / (float) shape.height, 
                       (float) new_shape.width / (float) shape.width);
    if (!scale_up) {
        r = std::min(r, 1.0f);
    }

    int new_unpad[2]{ (int) std::round((float) shape.width * r),
                     (int) std::round((float) shape.height * r)};
	...
}
```

在`letter_box`函数中，r是$\frac{新的高度}{新的宽度}$和$\frac{旧的高度}{旧的宽度}$两个比值的较小值，它的作用是为了在之后的`resize`中让新的图像保持合适的横纵比，防止缩放后的图像发生扭曲变形的情况。而`new_unpad`则是图像本身（不包含补边）缩放后的新形状大小，它的目的在于保持图像的横纵比不变。

<img src="/home/fss/.config/Typora/typora-user-images/image-20230906210442202.png" alt="image-20230906210442202" style="zoom:67%;" />

根据上图所示，蓝线部分代表经过`resize`后的图像大小，即`new_unpad`的大小；黄线部分则表示输出图像的整体大小。所以我们可以知道，由于`resize`后的图像不一定与输出大小匹配，比如我们将输入图像`resize`至 $520\times 640 $以保持比例，与目标大小$640\times 640$不符，这种情况下我们就需要进行图像补边，以将图像填充至指定的目标大小。

```cpp
float Letterbox(...){
    float dw = new_shape.width - new_unpad[0];
    float dh = new_shape.height - new_unpad[1];

    if (!fixed_shape) {
        dw = (float) ((int) dw % stride);
        dh = (float) ((int) dh % stride);
    }

    dw /= 2.0f;
    dh /= 2.0f;

    int top = int(std::round(dh - 0.1f));
    int bottom = int(std::round(dh + 0.1f));
    int left = int(std::round(dw - 0.1f));
    int right = int(std::round(dw + 0.1f));
    cv::copyMakeBorder(tmp, out_image, top, bottom, left, right, cv::BORDER_CONSTANT, color);

```

根据上图，`dw`和`dh`就是需要补边的大小，也就是蓝线和黄线之间的长度差距。我们使用 `cv::copyMakeBorder`对这个差距进行填充，填充的颜色是由`color`参数所指定的。经过图像缩放和补边，最终得到的图像大小为$640\times 640$.

### 颜色空间归一化

这样做的目的是为了将图像像素值映射到0-1之间，这可以减少量化误差，也使图像更容易被神经网络处理。因为原始的`RGB`值通常是0-255范围的整数，范围较大，通过归一化可以把值映射到一个更小的区间，有利于网络训练。

```cpp
kuiper_infer::sftensor PreProcessImage(const cv::Mat& image,
                                       const int32_t input_h,
                                       const int32_t input_w){
	...
    ...
    cv::Mat rgb_image;
    cv::cvtColor(out_image, rgb_image, cv::COLOR_BGR2RGB);

    cv::Mat normalize_image;
    rgb_image.convertTo(normalize_image, CV_32FC3, 1. / 255.);
```

### 颜色空间转换

正如上文所提到的，这里的颜色空间转换是将图像像素分布从`RGBRGBRGB` 转换到 `RRRGGGBBB`。也就是说，将像素的存储格式从原来的`HWC`(即高度-宽度-通道)转换为`CHW`(即通道-高度-宽度)。这个转换可以让之后的运算更加方便和高效，因为许多深度学习模型都采用`CHW`格式作为输入。

```cpp
kuiper_infer::sftensor PreProcessImage(const cv::Mat& image,
                                       const int32_t input_h,
                                       const int32_t input_w){
	...
    ...
    std::vector<cv::Mat> split_images;
    cv::split(normalize_image, split_images);
    assert(split_images.size() == input_c);

    std::shared_ptr<Tensor<float>> input =
        std::make_shared<Tensor<float>>(input_c, input_h, input_w);
    input->Fill(0.f);

    int index = 0;
    int offset = 0;
    for (const auto& split_image : split_images) {
        assert(split_image.total() == input_w * input_h);
        const cv::Mat& split_image_t = split_image.t();
        memcpy(input->slice(index).memptr(), split_image_t.data,
               sizeof(float) * split_image.total());
        index += 1;
        offset += split_image.total();
    }
```

首先，我们使用`cv::split`将图像的`RGB`三个通道拆分开来，分别存储到`split_images`数组中，同时准备好一个空的`input`张量来存储转换后的结果。

然后，再使用for循环来处理存储了拆分通道的`split_images`数组，在每次循环中，我们取出其中一个图像通道，由于`opencv`使用的是行主序存储，而我们是列主序存储，所以要对每个`split_image`进行转置.t()操作。经过这样的三次循环，我们将每个通道的数据（也就是R通道、G通道和B通道）逐通道的复制到`input`张量中，这样就可以实现从`HWC`格式到`CHW`格式。

**至此，我们就完成了图像预处理的全部流程。**

## 预处理函数的调用

todo

## 模型的加载

todo
